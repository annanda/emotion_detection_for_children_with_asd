# Multimodal Emotion Detection System

An end-to-end multimodal system to classify emotion zones. It supports three different type of input modalities, i.e. video, audio and physiological signals. 

This system does not extract features from raw files, the user needs to provide a dataset of extracted features. 

The system supports any combination of features and inputs listed below. 

## Modalities of input
- video
- audio
- physio

## Visual features list
- AU
- appearance
- BoVW
- geometric
- gaze
- 2d_eye_landmark
- 3d_eye_landmark
- head_pose

## Audio features list
- BoAW
- DeepSpectrum
- eGeMAPSfunct

## Physiological signals features list
- HRHRV
