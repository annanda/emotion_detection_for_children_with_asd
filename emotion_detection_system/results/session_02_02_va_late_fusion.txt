######################################
 ... Results for the data experiment: ... 

Participant number: 02
Session number: 02
All participant data: False
Sessions to consider: ['session_02_02']
Dataset split type: non_sequential
Person-Independent model: False
Modalities: ['video', 'audio']
Features type video: ['2d_eye_landmark', '3d_eye_landmark', 'AU', 'face_2d_landmarks', 'face_3d_landmarks', 'gaze', 'head_pose']
Features level audio: functionals
Features groups audio: ['frequency', 'energy_amplitude', 'spectral_balance', 'temporal_features']
Features type audio: {'frequency': ['pitch', 'jitter', 'formant_1-3_frequency', 'formant_1-3_bandwidth'], 'energy_amplitude': ['shimmer', 'loudness', 'harmonics-to-noise_ratio'], 'spectral_balance': ['alpha_ratio', 'hammarberg_index', 'spectral_slope', 'formant_1-3_relative_energy', 'harmonic_difference_H1–H2', 'Harmonic_difference_H1–A3', 'mfcc_1–4'], 'temporal_features': ['temporal_features']}
Models per modality: {'video': 'SVM', 'early_fusion_model': 'SVM', 'audio': 'SVM'}
Fusion type: late_fusion
###################################### 

Accuracy: 0.5688
Confusion matrix: labels=['blue', 'green', 'red', 'yellow']
[[  0 163   0   0]
 [  0 443   1   1]
 [  0  50  13   2]
 [  0 127   4   3]]
Total train examples: 6481
Number of examples per class in training: 
green     3578
blue      1306
yellow    1075
red        522
Name: emotion_zone, dtype: int64
Total test examples: 807
Total number of features: 744
Total number of video features: 669
Total number of audio features: 75
######################################
